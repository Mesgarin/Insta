{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ff87ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text    Sentiment  \\\n",
      "0   Just finished an amazing workout! ðŸ’ª       ...   Positive     \n",
      "1   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
      "2   The new movie release is a must-watch!       ...   Positive     \n",
      "3   Just published a new blog post. Check it out!...   Positive     \n",
      "4   New year, new fitness goals! ðŸ’ª            ...   Positive     \n",
      "\n",
      "          Timestamp            User     Platform  \\\n",
      "0  15-01-2023 15:45   FitnessFan      Instagram    \n",
      "1  15-01-2023 19:55   ChefCook        Instagram    \n",
      "2  16-01-2023 19:30   MovieBuff       Instagram    \n",
      "3  17-01-2023 15:15   BloggerX        Instagram    \n",
      "4  18-01-2023 18:00   FitJourney      Instagram    \n",
      "\n",
      "                                     Hashtags  Retweets  Likes       Country  \\\n",
      "0   #Fitness #Workout                                20     40   USA           \n",
      "1   #Cooking #Food                                   12     25    Australia    \n",
      "2    #MovieNight #MustWatch                          15     30       USA       \n",
      "3    #Blogging #NewPost                              22     45           USA   \n",
      "4    #NewYear #FitnessGoals                          28     55   USA           \n",
      "\n",
      "   Year  Month  Day  Hour  \n",
      "0  2023      1   15    15  \n",
      "1  2023      1   15    19  \n",
      "2  2023      1   16    19  \n",
      "3  2023      1   17    15  \n",
      "4  2023      1   18    18  \n",
      "Index(['Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags',\n",
      "       'Retweets', 'Likes', 'Country', 'Year', 'Month', 'Day', 'Hour'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the data\n",
    "df = pd.read_csv(\"Data/instagramcommentdataset.csv\")\n",
    "\n",
    "# see the data\n",
    "print(df.head())\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4571cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_model = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\"  # یا \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1c6f41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.9496434330940247}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model(\"I really love this phone, it is amazing!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "576c1c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>bert_sentiment_label</th>\n",
       "      <th>bert_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just finished an amazing workout! ðŸ’ª       ...</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>0.859115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>4 stars</td>\n",
       "      <td>0.360886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The new movie release is a must-watch!       ...</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>0.861503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just published a new blog post. Check it out!...</td>\n",
       "      <td>1 star</td>\n",
       "      <td>0.301508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New year, new fitness goals! ðŸ’ª            ...</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>0.780261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text bert_sentiment_label  \\\n",
       "0   Just finished an amazing workout! ðŸ’ª       ...              5 stars   \n",
       "1   Trying out a new recipe for dinner tonight.  ...              4 stars   \n",
       "2   The new movie release is a must-watch!       ...              5 stars   \n",
       "3   Just published a new blog post. Check it out!...               1 star   \n",
       "4   New year, new fitness goals! ðŸ’ª            ...              5 stars   \n",
       "\n",
       "   bert_sentiment_score  \n",
       "0              0.859115  \n",
       "1              0.360886  \n",
       "2              0.861503  \n",
       "3              0.301508  \n",
       "4              0.780261  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "texts = df['Text'].astype(str).tolist()\n",
    "batch_size = 32\n",
    "\n",
    "labels = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    preds = sentiment_model(batch)\n",
    "    labels.extend(preds)\n",
    "\n",
    "# تبدیل خروجی مدل به دو ستون: label و score\n",
    "df['bert_sentiment_label'] = [x['label'] for x in labels]\n",
    "df['bert_sentiment_score'] = [x['score'] for x in labels]\n",
    "\n",
    "# نگاهی به چند سطر\n",
    "df[['Text', 'bert_sentiment_label', 'bert_sentiment_score']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23c855d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stars_to_polarity(label):\n",
    "    # label مثل \"1 star\" یا \"5 stars\"\n",
    "    n = int(label.split()[0])\n",
    "    if n <= 2:\n",
    "        return \"negative\"\n",
    "    elif n == 3:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "df['bert_sentiment_polarity'] = df['bert_sentiment_label'].apply(stars_to_polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6faecb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bert_sentiment_polarity\n",
       "positive    216\n",
       "negative     35\n",
       "neutral       7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bert_sentiment_polarity'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48ab5e",
   "metadata": {},
   "source": [
    "we want to find the best hashtag for ech comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c217031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hashtags'] = df['Hashtags'].fillna('').astype(str)\n",
    "df['Hashtags_lower'] = df['Hashtags'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9886573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Text, Sentiment, Timestamp, User, Platform, Hashtags, Retweets, Likes, Country, Year, Month, Day, Hour, bert_sentiment_label, bert_sentiment_score, bert_sentiment_polarity, Hashtags_lower]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def filter_by_hashtag(df, hashtag):\n",
    "    hashtag = hashtag.lower()\n",
    "    mask = df['Hashtags_lower'].str.contains(rf'\\b{hashtag}\\b', na=False)\n",
    "    return df[mask]\n",
    "\n",
    "df_newyear = filter_by_hashtag(df, '#newyear')\n",
    "print(df_newyear.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a68e99e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text    Sentiment  \\\n",
      "0   Just finished an amazing workout! ðŸ’ª       ...   Positive     \n",
      "1   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
      "2   The new movie release is a must-watch!       ...   Positive     \n",
      "3   Just published a new blog post. Check it out!...   Positive     \n",
      "4   New year, new fitness goals! ðŸ’ª            ...   Positive     \n",
      "\n",
      "          Timestamp            User     Platform  \\\n",
      "0  15-01-2023 15:45   FitnessFan      Instagram    \n",
      "1  15-01-2023 19:55   ChefCook        Instagram    \n",
      "2  16-01-2023 19:30   MovieBuff       Instagram    \n",
      "3  17-01-2023 15:15   BloggerX        Instagram    \n",
      "4  18-01-2023 18:00   FitJourney      Instagram    \n",
      "\n",
      "                                     Hashtags  Retweets  Likes       Country  \\\n",
      "0   #Fitness #Workout                                20     40   USA           \n",
      "1   #Cooking #Food                                   12     25    Australia    \n",
      "2    #MovieNight #MustWatch                          15     30       USA       \n",
      "3    #Blogging #NewPost                              22     45           USA   \n",
      "4    #NewYear #FitnessGoals                          28     55   USA           \n",
      "\n",
      "   Year  Month  Day  Hour bert_sentiment_label  bert_sentiment_score  \\\n",
      "0  2023      1   15    15              5 stars              0.859115   \n",
      "1  2023      1   15    19              4 stars              0.360886   \n",
      "2  2023      1   16    19              5 stars              0.861503   \n",
      "3  2023      1   17    15               1 star              0.301508   \n",
      "4  2023      1   18    18              5 stars              0.780261   \n",
      "\n",
      "  bert_sentiment_polarity                              Hashtags_lower  \n",
      "0                positive   #fitness #workout                          \n",
      "1                positive   #cooking #food                             \n",
      "2                positive    #movienight #mustwatch                    \n",
      "3                negative    #blogging #newpost                        \n",
      "4                positive    #newyear #fitnessgoals                    \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cafb9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Hashtags values:\n",
      "0          #Fitness #Workout                        \n",
      "1          #Cooking #Food                           \n",
      "2           #MovieNight #MustWatch                  \n",
      "3           #Blogging #NewPost                      \n",
      "4           #NewYear #FitnessGoals                  \n",
      "5           #PetAdoption #FurryFriend               \n",
      "6           #WinterBlues #Mood                      \n",
      "7             #Productivity #WorkFromHome           \n",
      "8            #Brunch #Friends                       \n",
      "9           #Reading #QuietTime                     \n",
      "10          #RoadTrip #ScenicViews                  \n",
      "11          #Inspiration #Workshop                  \n",
      "12            #Music #ConcertNight                  \n",
      "13          #Gaming #Tournament                     \n",
      "14             #Accomplished #Success               \n",
      "15           #BookRelease #FavoriteAuthor           \n",
      "16           #Cooking #SpecialDinner                \n",
      "17           #BikeRide #ScenicTrails                \n",
      "18     #Fear #ThrillerMovie                         \n",
      "19        #Happiness #Celebration                   \n",
      "Name: Hashtags, dtype: object\n",
      "\n",
      "Lowercased version:\n",
      "0          #fitness #workout                        \n",
      "1          #cooking #food                           \n",
      "2           #movienight #mustwatch                  \n",
      "3           #blogging #newpost                      \n",
      "4           #newyear #fitnessgoals                  \n",
      "5           #petadoption #furryfriend               \n",
      "6           #winterblues #mood                      \n",
      "7             #productivity #workfromhome           \n",
      "8            #brunch #friends                       \n",
      "9           #reading #quiettime                     \n",
      "10          #roadtrip #scenicviews                  \n",
      "11          #inspiration #workshop                  \n",
      "12            #music #concertnight                  \n",
      "13          #gaming #tournament                     \n",
      "14             #accomplished #success               \n",
      "15           #bookrelease #favoriteauthor           \n",
      "16           #cooking #specialdinner                \n",
      "17           #bikeride #scenictrails                \n",
      "18     #fear #thrillermovie                         \n",
      "19        #happiness #celebration                   \n",
      "Name: Hashtags_lower, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Hashtags values:\")\n",
    "print(df['Hashtags'].head(20))\n",
    "\n",
    "print(\"\\nLowercased version:\")\n",
    "print(df['Hashtags_lower'].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18cb9cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Hashtags  \\\n",
      "4   #NewYear #FitnessGoals                     \n",
      "\n",
      "                                                Text  \n",
      "4   New year, new fitness goals! ðŸ’ª            ...  \n"
     ]
    }
   ],
   "source": [
    "df_newyear = df[df['Hashtags'].str.contains('newyear', case=False, na=False)]\n",
    "print(df_newyear[['Hashtags', 'Text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f1a0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_hashtag(df, hashtag):\n",
    "    # حذف # از اول برای انعطاف بیشتر: 'newyear' یا '#newyear' هر دو اوکی\n",
    "    tag = hashtag.lower().lstrip('#')\n",
    "    \n",
    "    # مطمئن می‌شویم ستون Hashtags_lower را داریم\n",
    "    if 'Hashtags_lower' not in df.columns:\n",
    "        df['Hashtags'] = df['Hashtags'].fillna('').astype(str)\n",
    "        df['Hashtags_lower'] = df['Hashtags'].str.lower()\n",
    "    \n",
    "    # همین که متن شامل newyear باشد کافی است\n",
    "    mask = df['Hashtags_lower'].str.contains(tag, na=False)\n",
    "    return df[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ecf33bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Hashtags  \\\n",
      "4   #NewYear #FitnessGoals                     \n",
      "\n",
      "                                                Text  \n",
      "4   New year, new fitness goals! ðŸ’ª            ...  \n"
     ]
    }
   ],
   "source": [
    "df_newyear = filter_by_hashtag(df, '#newyear')\n",
    "print(df_newyear[['Hashtags', 'Text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c824d3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Hashtags  \\\n",
      "4   #NewYear #FitnessGoals                     \n",
      "\n",
      "                                                Text  \n",
      "4   New year, new fitness goals! ðŸ’ª            ...  \n"
     ]
    }
   ],
   "source": [
    "df_newyear = filter_by_hashtag(df, 'newyear')\n",
    "\n",
    "print(df_newyear[['Hashtags', 'Text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ace881",
   "metadata": {},
   "source": [
    "find the sentiment for specific hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b72d195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bert_sentiment_polarity\n",
       "positive    1.0\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_newyear['bert_sentiment_polarity'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2f78b7",
   "metadata": {},
   "source": [
    "which countries have this hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd52b26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "USA            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_newyear['Country'].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f15cd27",
   "metadata": {},
   "source": [
    "when this hashtag was seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "548261eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year  Month\n",
       "2023  1        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_newyear.groupby(['Year', 'Month']).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "240c3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "kw_model = KeyBERT(model='all-MiniLM-L6-v2')  # از sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "195db0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('camera quality', 0.7083), ('quality phone', 0.6794), ('phone amazing', 0.5526), ('camera', 0.4626), ('low light', 0.4621)]\n"
     ]
    }
   ],
   "source": [
    "text = \"The camera quality of this phone is amazing, especially in low light.\"\n",
    "keywords = kw_model.extract_keywords(\n",
    "    text,\n",
    "    keyphrase_ngram_range=(1, 2),  # تک‌کلمه‌ای و دوکلمه‌ای\n",
    "    stop_words='english',\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "print(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8f0eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_to_hashtags(text, top_n=5):\n",
    "    if not isinstance(text, str) or text.strip() == '':\n",
    "        return []\n",
    "\n",
    "    keywords = kw_model.extract_keywords(\n",
    "        text,\n",
    "        keyphrase_ngram_range=(1, 2),\n",
    "        stop_words='english',\n",
    "        top_n=top_n\n",
    "    )\n",
    "\n",
    "    tags = []\n",
    "    for kw, score in keywords:\n",
    "        # حذف کاراکترهای غیرحرفی/عددی\n",
    "        kw_clean = re.sub(r'[^a-zA-Z0-9\\s]', '', kw)\n",
    "        if not kw_clean:\n",
    "            continue\n",
    "        # حذف فاصله و تبدیل به هشتگ\n",
    "        tag = '#' + kw_clean.replace(' ', '').lower()\n",
    "        tags.append(tag)\n",
    "\n",
    "    # یکتا کردن ترتیب حفظ شود\n",
    "    tags_unique = list(dict.fromkeys(tags))\n",
    "    return tags_unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "480d1c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#cameraquality', '#qualityphone', '#phoneamazing', '#camera', '#lowlight']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_hashtags(\"The camera quality of this phone is amazing, especially in low light.\")\n",
    "# مثال خروجی: ['#cameraquality', '#lowlight', '#phone']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25dca6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>suggested_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just finished an amazing workout! ðŸ’ª       ...</td>\n",
       "      <td>#workout #amazingworkout #finishedamazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>#newrecipe #recipedinner #recipe #dinnertonigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The new movie release is a must-watch!       ...</td>\n",
       "      <td>#newmovie #movierelease #releasewatch #movie #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just published a new blog post. Check it out!...</td>\n",
       "      <td>#newblog #blogpost #justpublished #blog #publi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New year, new fitness goals! ðŸ’ª            ...</td>\n",
       "      <td>#newfitness #fitnessgoals #fitness #goals #new...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0   Just finished an amazing workout! ðŸ’ª       ...   \n",
       "1   Trying out a new recipe for dinner tonight.  ...   \n",
       "2   The new movie release is a must-watch!       ...   \n",
       "3   Just published a new blog post. Check it out!...   \n",
       "4   New year, new fitness goals! ðŸ’ª            ...   \n",
       "\n",
       "                                  suggested_hashtags  \n",
       "0          #workout #amazingworkout #finishedamazing  \n",
       "1  #newrecipe #recipedinner #recipe #dinnertonigh...  \n",
       "2  #newmovie #movierelease #releasewatch #movie #...  \n",
       "3  #newblog #blogpost #justpublished #blog #publi...  \n",
       "4  #newfitness #fitnessgoals #fitness #goals #new...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['suggested_hashtags_list'] = df['Text'].apply(text_to_hashtags)\n",
    "\n",
    "# اگر بخوای به صورت رشته‌ی قابل‌خواندن داشته باشی:\n",
    "df['suggested_hashtags'] = df['suggested_hashtags_list'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "df[['Text', 'suggested_hashtags']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8444f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique hashtags: 411\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def split_hashtags(s):\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    # جدا کردن بر اساس فاصله و کاما\n",
    "    parts = re.split(r'[\\s,]+', s)\n",
    "    # فقط مواردی که با # شروع می‌شوند\n",
    "    return [p.strip().lower() for p in parts if p.strip().startswith('#')]\n",
    "\n",
    "all_tags = list(itertools.chain.from_iterable(df['Hashtags'].apply(split_hashtags)))\n",
    "unique_tags = sorted(set(all_tags))\n",
    "\n",
    "print(\"Number of unique hashtags:\", len(unique_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae14a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(all_tags)\n",
    "candidate_tags = [tag for tag, c in counter.most_common(5)]  # مثلاً ۲۰۰۰ هشتگ برتر\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df9eafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "st_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# ۱) امبدینگ هشتگ‌ها (فقط یک‌بار)\n",
    "hashtag_embeddings = st_model.encode(candidate_tags, normalize_embeddings=True)\n",
    "hashtag_embeddings = np.array(hashtag_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d7624e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_hashtags_from_vocab(text, top_n=5):\n",
    "    if not isinstance(text, str) or text.strip() == '':\n",
    "        return []\n",
    "\n",
    "    text_emb = st_model.encode([text], normalize_embeddings=True)[0]  # (dim,)\n",
    "    # شباهت کسینوسی با ضرب داخلی چون نرمال کردیم\n",
    "    sims = hashtag_embeddings @ text_emb  # shape: (num_tags,)\n",
    "\n",
    "    # ایندکس‌های top_n\n",
    "    top_idx = np.argsort(-sims)[:top_n]\n",
    "    return [candidate_tags[i] for i in top_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0708908b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#enthusiasm', '#curiosity', '#serenity', '#euphoria', '#confusion']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_hashtags_from_vocab(\"The battery life of this phone is amazing\", top_n=5)\n",
    "# خروجی: مثلاً ['#battery', '#smartphone', '#iphone', ...] (بسته به داده‌هایت)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ac541c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>suggested_hashtags_vocab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just finished an amazing workout! ðŸ’ª       ...</td>\n",
       "      <td>#enthusiasm #curiosity #euphoria #confusion #s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>#confusion #enthusiasm #curiosity #euphoria #s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The new movie release is a must-watch!       ...</td>\n",
       "      <td>#serenity #confusion #enthusiasm #curiosity #e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just published a new blog post. Check it out!...</td>\n",
       "      <td>#serenity #euphoria #curiosity #enthusiasm #co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New year, new fitness goals! ðŸ’ª            ...</td>\n",
       "      <td>#enthusiasm #curiosity #euphoria #confusion #s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0   Just finished an amazing workout! ðŸ’ª       ...   \n",
       "1   Trying out a new recipe for dinner tonight.  ...   \n",
       "2   The new movie release is a must-watch!       ...   \n",
       "3   Just published a new blog post. Check it out!...   \n",
       "4   New year, new fitness goals! ðŸ’ª            ...   \n",
       "\n",
       "                            suggested_hashtags_vocab  \n",
       "0  #enthusiasm #curiosity #euphoria #confusion #s...  \n",
       "1  #confusion #enthusiasm #curiosity #euphoria #s...  \n",
       "2  #serenity #confusion #enthusiasm #curiosity #e...  \n",
       "3  #serenity #euphoria #curiosity #enthusiasm #co...  \n",
       "4  #enthusiasm #curiosity #euphoria #confusion #s...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['suggested_hashtags_vocab'] = df['Text'].apply(\n",
    "    lambda x: ' '.join(recommend_hashtags_from_vocab(x, top_n=5))\n",
    ")\n",
    "\n",
    "df[['Text', 'suggested_hashtags_vocab']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca86bcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# حذف ردیف‌هایی که متن ندارند\n",
    "df_topic = df[df['Text'].notna()].copy()\n",
    "\n",
    "# لیست متن‌ها برای ورودی BERTopic\n",
    "docs = df_topic['Text'].astype(str).tolist()\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de343caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 11:58:17,454 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7d163e52964aa09c8d8cab8c624a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 11:58:21,628 - BERTopic - Embedding - Completed ✓\n",
      "2025-11-13 11:58:21,632 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-11-13 11:58:40,958 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-11-13 11:58:40,962 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-11-13 11:58:40,989 - BERTopic - Cluster - Completed ✓\n",
      "2025-11-13 11:58:40,999 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-11-13 11:58:41,043 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# مدل امبدینگ (سریع و خوب برای انگلیسی)\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,   # می‌تونی None هم بگذاری و از پیش‌فرض استفاده کنی\n",
    "    language=\"english\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6813f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic['topic'] = topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbb61f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(\n",
    "    df_topic[['Text', 'topic']],\n",
    "    on='Text',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd30e2e",
   "metadata": {},
   "source": [
    "معمولاً ستون‌ها چیزی مثل این‌اند:\n",
    "\n",
    "Topic → شماره‌ی topic (مثلاً 0،1،2،...)\n",
    "\n",
    "Count → چندتا داکیومنت توی این topic\n",
    "\n",
    "Name → چند کلمه‌ی نماینده‌ی اون topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "313abb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                     Name  \\\n",
      "0     -1     39         -1_the_of_in_and   \n",
      "1      0    110          0_the_of_new_in   \n",
      "2      1     59       1_of_the_in_echoes   \n",
      "3      2     38           2_the_of_by_in   \n",
      "4      3     12  3_concert_at_of_harmony   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [the, of, in, and, as, for, to, with, joy, trail]   \n",
      "1    [the, of, new, in, for, and, to, with, on, art]   \n",
      "2  [of, the, in, echoes, to, emotions, feeling, e...   \n",
      "3  [the, of, by, in, sunset, colors, nature, canv...   \n",
      "4  [concert, at, of, harmony, resonates, tribute,...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [As the movie credits roll, the viewer experie...  \n",
      "1  [In the realm of fashion, the designer unveils...  \n",
      "2  [ Wrapped in the cloak of emotional numbness, ...  \n",
      "3  [ Embraced by the hopeful dawn, a gardener sow...  \n",
      "4  [Swaying to the reggae vibes of Bob Marley's t...  \n"
     ]
    }
   ],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b615e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('concert', 0.1537633934929388),\n",
       " ('at', 0.10331566222196363),\n",
       " ('of', 0.09756196233852563),\n",
       " ('harmony', 0.09645065456472295),\n",
       " ('resonates', 0.09645065456472295),\n",
       " ('tribute', 0.09645065456472295),\n",
       " ('to', 0.09435150245531224),\n",
       " ('soul', 0.08408239805879363),\n",
       " ('with', 0.0696581886298484),\n",
       " ('musicians', 0.06913769513386436)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e37a6cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       " 0    110\n",
       " 1     59\n",
       "-1     39\n",
       " 2     38\n",
       " 3     12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic['topic'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56c24f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "-1     39\n",
       " 0    110\n",
       " 1     59\n",
       " 2     38\n",
       " 3     12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic['topic'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bcb585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic\n",
      " 3    55.833333\n",
      " 2    49.263158\n",
      " 0    47.736364\n",
      "-1    44.769231\n",
      " 1    35.491525\n",
      "Name: Likes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "likes_by_topic = df_topic.groupby('topic')['Likes'].mean().sort_values(ascending=False)\n",
    "print(likes_by_topic.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b113a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic\n",
      " 3    28.000000\n",
      " 2    24.605263\n",
      " 0    23.936364\n",
      "-1    22.538462\n",
      " 1    17.762712\n",
      "Name: Retweets, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "retweets_by_topic = df_topic.groupby('topic')['Retweets'].mean().sort_values(ascending=False)\n",
    "print(retweets_by_topic.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "207e6ab0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m topic_model\u001b[38;5;241m.\u001b[39mget_topic(\u001b[43mtopic_id\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'topic_id' is not defined"
     ]
    }
   ],
   "source": [
    "topic_model.get_topic(topic_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ae4972e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_sentiment_polarity  negative  neutral  positive\n",
      "topic                                               \n",
      "-1                              6        1        32\n",
      " 0                              9        0       101\n",
      " 1                             19        5        35\n",
      " 2                              1        0        37\n",
      " 3                              0        1        11\n"
     ]
    }
   ],
   "source": [
    "sent_by_topic = (\n",
    "    df_topic\n",
    "    .groupby(['topic', 'bert_sentiment_polarity'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "print(sent_by_topic.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5221d371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_sentiment_polarity  negative   neutral  positive\n",
      "topic                                                \n",
      "-1                       0.153846  0.025641  0.820513\n",
      " 0                       0.081818  0.000000  0.918182\n",
      " 1                       0.322034  0.084746  0.593220\n",
      " 2                       0.026316  0.000000  0.973684\n",
      " 3                       0.000000  0.083333  0.916667\n"
     ]
    }
   ],
   "source": [
    "sent_by_topic_pct = sent_by_topic.div(sent_by_topic.sum(axis=1), axis=0)\n",
    "print(sent_by_topic_pct.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd00d81",
   "metadata": {},
   "source": [
    "relationship between topics and hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb2d212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "\n",
    "def split_hashtags(s):\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    parts = re.split(r'[\\s,]+', s.strip())\n",
    "    return [p for p in parts if p.startswith('#') and p != '#']\n",
    "\n",
    "# ساخت یک نسخه‌ی explode شده\n",
    "df_tags = df_topic.copy()\n",
    "df_tags['hashtag_list'] = df_tags['Hashtags'].apply(split_hashtags)\n",
    "\n",
    "df_exploded = df_tags.explode('hashtag_list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bf2615d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     topic     hashtag_list  count\n",
      "422      3         #Harmony      2\n",
      "429      3    #MusicalUnity      2\n",
      "415      3    #AdeleConcert      1\n",
      "427      3           #Music      1\n",
      "435      3       #TeenMusic      1\n",
      "434      3  #SoulUpliftment      1\n",
      "433      3    #SeniorVoices      1\n",
      "432      3    #QueenTribute      1\n",
      "431      3      #Positivity      1\n",
      "430      3       #Nostalgia      1\n"
     ]
    }
   ],
   "source": [
    "top_tags_per_topic = (\n",
    "    df_exploded\n",
    "    .groupby(['topic', 'hashtag_list'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# مثلاً top 10 هشتگ برای topic شماره 3:\n",
    "topic_id = 3\n",
    "top_tags_topic3 = (\n",
    "    top_tags_per_topic[top_tags_per_topic['topic'] == topic_id]\n",
    "    .sort_values('count', ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "print(top_tags_topic3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "125f2d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FINAL TOPIC REPORT =====\n",
      "   Topic                         Top Keywords  Avg Likes  Avg Retweets  \\\n",
      "3      3  concert, at, of, harmony, resonates      55.83         28.00   \n",
      "2      2              the, of, by, in, sunset      49.26         24.61   \n",
      "0      0                the, of, new, in, for      47.74         23.94   \n",
      "1      1              of, the, in, echoes, to      35.49         17.76   \n",
      "\n",
      "  Dominant Sentiment                        Top 3 Hashtags  \n",
      "3           positive  #Harmony #MusicalUnity #AdeleConcert  \n",
      "2           positive            #Serenity #Hopeful #Wonder  \n",
      "0           positive          #Excitement #Surprise #Pride  \n",
      "1           positive       #Confusion #Despair #Bitterness  \n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "#   FULL TOPIC ANALYSIS REPORT (ONE-BLOCK)\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# -----------------------------\n",
    "# 1) استخراج کلمات کلیدی هر Topic\n",
    "# -----------------------------\n",
    "\n",
    "topic_keywords = {}\n",
    "for topic_id in topic_model.get_topic_info()['Topic'].tolist():\n",
    "    if topic_id == -1:\n",
    "        continue  # حذف outlierها\n",
    "    words = topic_model.get_topic(topic_id)\n",
    "    if words is None:\n",
    "        continue\n",
    "    topic_keywords[topic_id] = \", \".join([w[0] for w in words[:5]])  # ۵ کلمه کلیدی برتر\n",
    "\n",
    "# -----------------------------\n",
    "# 2) میانگین لایک و ریتوییت\n",
    "# -----------------------------\n",
    "\n",
    "likes_by_topic = df_topic.groupby('topic')['Likes'].mean()\n",
    "retweets_by_topic = df_topic.groupby('topic')['Retweets'].mean()\n",
    "\n",
    "# -----------------------------\n",
    "# 3) احساس غالب هر Topic\n",
    "# -----------------------------\n",
    "\n",
    "dominant_sentiment = (\n",
    "    df_topic\n",
    "    .groupby(['topic', 'bert_sentiment_polarity'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# تبدیل به احساس غالب\n",
    "sent_dict = {}\n",
    "for topic_id in dominant_sentiment['topic'].unique():\n",
    "    temp = dominant_sentiment[dominant_sentiment['topic'] == topic_id]\n",
    "    top_row = temp.sort_values('count', ascending=False).iloc[0]\n",
    "    sent_dict[topic_id] = top_row['bert_sentiment_polarity']\n",
    "\n",
    "# -----------------------------\n",
    "# 4) پرتکرارترین هشتگ‌های هر Topic\n",
    "# -----------------------------\n",
    "\n",
    "# تبدیل Hashtags به لیست\n",
    "def split_hashtags(s):\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    parts = re.split(r'[\\s,]+', s.strip())\n",
    "    return [p for p in parts if p.startswith('#') and len(p) > 1]\n",
    "\n",
    "df_topic['hashtag_list'] = df_topic['Hashtags'].apply(split_hashtags)\n",
    "\n",
    "# explode برای شمارش راحت‌تر\n",
    "df_hash = df_topic.explode('hashtag_list')\n",
    "\n",
    "# شمارش\n",
    "top_hashtags = (\n",
    "    df_hash.groupby(['topic','hashtag_list'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "top3_tags_per_topic = {}\n",
    "for topic_id in df_topic['topic'].unique():\n",
    "    temp = top_hashtags[top_hashtags['topic'] == topic_id]\n",
    "    if len(temp) == 0:\n",
    "        top3_tags_per_topic[topic_id] = \"\"\n",
    "    else:\n",
    "        top3 = temp.sort_values('count', ascending=False)['hashtag_list'].head(3)\n",
    "        top3_tags_per_topic[topic_id] = \" \".join(top3.tolist())\n",
    "\n",
    "# -----------------------------\n",
    "# 5) ساخت جدول نهایی\n",
    "# -----------------------------\n",
    "\n",
    "report = []\n",
    "for topic_id in sorted(df_topic['topic'].unique()):\n",
    "    if topic_id == -1:\n",
    "        continue\n",
    "    report.append({\n",
    "        \"Topic\": topic_id,\n",
    "        \"Top Keywords\": topic_keywords.get(topic_id, \"\"),\n",
    "        \"Avg Likes\": round(likes_by_topic.get(topic_id, 0), 2),\n",
    "        \"Avg Retweets\": round(retweets_by_topic.get(topic_id, 0), 2),\n",
    "        \"Dominant Sentiment\": sent_dict.get(topic_id, \"\"),\n",
    "        \"Top 3 Hashtags\": top3_tags_per_topic.get(topic_id, \"\")\n",
    "    })\n",
    "\n",
    "report_df = pd.DataFrame(report)\n",
    "report_df = report_df.sort_values(\"Avg Likes\", ascending=False)  # مرتب‌سازی به دلخواه\n",
    "\n",
    "print(\"\\n===== FINAL TOPIC REPORT =====\")\n",
    "print(report_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26b60e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== AUTO-GENERATED TOPIC REPORT ======\n",
      "   Topic ID         Auto Title                  Keywords  Avg Likes  \\\n",
      "3         3  Concert / At (Of)  concert, at, of, harmony      55.83   \n",
      "2         2      The / Of (By)           the, of, by, in      49.26   \n",
      "0         0     The / Of (New)          the, of, new, in      47.74   \n",
      "1         1      Of / The (In)       of, the, in, echoes      35.49   \n",
      "\n",
      "   Avg Retweets Dominant Sentiment                          Top Hashtags  \n",
      "3         28.00           positive  #Harmony #MusicalUnity #AdeleConcert  \n",
      "2         24.61           positive            #Serenity #Hopeful #Wonder  \n",
      "0         23.94           positive          #Excitement #Surprise #Pride  \n",
      "1         17.76           positive       #Confusion #Despair #Bitterness  \n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "#     AUTO TITLE GENERATOR FOR BERTopic Topics\n",
    "# ====================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1) گرفتن کلمات کلیدی هر Topic\n",
    "topic_info = topic_model.get_topic_info()\n",
    "topic_ids = topic_info[topic_info['Topic'] != -1]['Topic'].tolist()\n",
    "\n",
    "topic_keywords = {}\n",
    "for topic_id in topic_ids:\n",
    "    words = topic_model.get_topic(topic_id)\n",
    "    if words is None:\n",
    "        continue\n",
    "    # فقط 3 تا 5 کلمه برتر\n",
    "    top_words = [w[0] for w in words[:4]]\n",
    "    topic_keywords[topic_id] = top_words\n",
    "\n",
    "# 2) تولید عنوان انسانی با ترکیب کلمات\n",
    "def make_title(words):\n",
    "    if not words:\n",
    "        return \"Unknown Topic\"\n",
    "    # اگر فقط یک کلمه\n",
    "    if len(words) == 1:\n",
    "        return words[0].capitalize()\n",
    "    # اگر دو کلمه\n",
    "    if len(words) == 2:\n",
    "        return f\"{words[0].capitalize()} & {words[1].capitalize()}\"\n",
    "    # اگر چند کلمه → دو کلمه‌ی اصلی + یک توضیح\n",
    "    return f\"{words[0].capitalize()} / {words[1].capitalize()} ({words[2].capitalize()})\"\n",
    "\n",
    "topic_titles = {tid: make_title(words) for tid, words in topic_keywords.items()}\n",
    "\n",
    "# 3) محاسبه میانگین لایک و ریتوییت\n",
    "likes_by_topic = df_topic.groupby('topic')['Likes'].mean().round(2)\n",
    "retweets_by_topic = df_topic.groupby('topic')['Retweets'].mean().round(2)\n",
    "\n",
    "# 4) احساس غالب\n",
    "sentiment_df = (\n",
    "    df_topic\n",
    "    .groupby(['topic', 'bert_sentiment_polarity'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "dominant_sentiment = {}\n",
    "for tid in topic_ids:\n",
    "    temp = sentiment_df[sentiment_df['topic'] == tid]\n",
    "    if len(temp) == 0:\n",
    "        dominant_sentiment[tid] = \"Unknown\"\n",
    "    else:\n",
    "        dominant_sentiment[tid] = (\n",
    "            temp.sort_values('count', ascending=False).iloc[0]['bert_sentiment_polarity']\n",
    "        )\n",
    "\n",
    "# 5) پرتکرارترین هشتگ‌های هر Topic\n",
    "import re\n",
    "\n",
    "def split_hashtags(s):\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    parts = re.split(r'[\\s,]+', s.strip())\n",
    "    return [p for p in parts if p.startswith('#')]\n",
    "\n",
    "df_topic['hashtag_list'] = df_topic['Hashtags'].apply(split_hashtags)\n",
    "df_hash = df_topic.explode('hashtag_list')\n",
    "\n",
    "top_tags = (\n",
    "    df_hash.groupby(['topic','hashtag_list'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "top_3_tags = {}\n",
    "for tid in topic_ids:\n",
    "    temp = top_tags[top_tags['topic'] == tid]\n",
    "    if len(temp) == 0:\n",
    "        top_3_tags[tid] = \"\"\n",
    "    else:\n",
    "        tags = temp.sort_values('count', ascending=False)['hashtag_list'].head(3)\n",
    "        top_3_tags[tid] = \" \".join(tags.tolist())\n",
    "\n",
    "# 6) ساخت جدول نهایی\n",
    "report = []\n",
    "for tid in topic_ids:\n",
    "    report.append({\n",
    "        \"Topic ID\": tid,\n",
    "        \"Auto Title\": topic_titles.get(tid, \"\"),\n",
    "        \"Keywords\": \", \".join(topic_keywords.get(tid, [])),\n",
    "        \"Avg Likes\": likes_by_topic.get(tid, 0),\n",
    "        \"Avg Retweets\": retweets_by_topic.get(tid, 0),\n",
    "        \"Dominant Sentiment\": dominant_sentiment.get(tid, \"\"),\n",
    "        \"Top Hashtags\": top_3_tags.get(tid, \"\")\n",
    "    })\n",
    "\n",
    "topic_report = pd.DataFrame(report)\n",
    "topic_report = topic_report.sort_values(\"Avg Likes\", ascending=False)\n",
    "\n",
    "print(\"\\n====== AUTO-GENERATED TOPIC REPORT ======\")\n",
    "print(topic_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9132e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Nastaran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nastaran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nastaran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Art\n",
      "Topic 1: Echoes Emotions\n",
      "Topic 2: Sunset Colors\n",
      "Topic 3: Concert Harmony\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# BETTER AUTO TITLES FOR TOPICS (Stopwords Removed)\n",
    "# =======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "\n",
    "# اگر دانلود نکردی:\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_keywords(words):\n",
    "    cleaned = []\n",
    "    for w in words:\n",
    "        w_clean = re.sub(r'[^a-zA-Z]', '', w).lower()\n",
    "        if len(w_clean) < 3: continue\n",
    "        if w_clean in STOPWORDS: continue\n",
    "        cleaned.append(w_clean)\n",
    "    return cleaned\n",
    "\n",
    "def select_main_words(words):\n",
    "    # POS tagging\n",
    "    tagged = pos_tag(words)\n",
    "    # فقط noun و verb مهم\n",
    "    filtered = [w for w, tag in tagged if tag.startswith('NN') or tag.startswith('VB')]\n",
    "    return filtered if filtered else words\n",
    "\n",
    "def make_better_title(words):\n",
    "    if not words:\n",
    "        return \"Unknown Topic\"\n",
    "    words = clean_keywords(words)\n",
    "    words = select_main_words(words)\n",
    "    if not words:\n",
    "        return \"Unnamed Topic\"\n",
    "\n",
    "    if len(words) == 1:\n",
    "        return words[0].capitalize()\n",
    "    if len(words) == 2:\n",
    "        return f\"{words[0].capitalize()} & {words[1].capitalize()}\"\n",
    "    return f\"{words[0].capitalize()} {words[1].capitalize()}\"\n",
    "\n",
    "# ------------------------------\n",
    "# استخراج عناوین جدید\n",
    "# ------------------------------\n",
    "\n",
    "topic_titles_better = {}\n",
    "\n",
    "for topic_id in topic_info['Topic'].tolist():\n",
    "    if topic_id == -1:\n",
    "        continue\n",
    "    words_raw = topic_model.get_topic(topic_id)\n",
    "    if words_raw is None:\n",
    "        continue\n",
    "    top_words = [w[0] for w in words_raw[:10]]\n",
    "    topic_titles_better[topic_id] = make_better_title(top_words)\n",
    "\n",
    "# نمایش نتایج\n",
    "for tid, title in topic_titles_better.items():\n",
    "    print(f\"Topic {tid}: {title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29d709a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     #Fitness #Workout                        \n",
      "1     #Cooking #Food                           \n",
      "2      #MovieNight #MustWatch                  \n",
      "3      #Blogging #NewPost                      \n",
      "4      #NewYear #FitnessGoals                  \n",
      "Name: Hashtags, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['Hashtags'].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
